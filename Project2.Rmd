---
title: "ST558 Project 2: Bike Sharing Analysis"
author: "Lynn Huang"
date: "September 18, 2020"
output:
  rmarkdown::github_document:
    toc: true
params:
  day: 0
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
# Cannot have rm() to remove the params list!
#rm(list=ls())
library(knitr)
library(tidyverse)
library(ggplot2)
library(caret)
library(rpart)
print(params$day)
#setwd("C:/Users/lynn/Documents/GitHub/ST558-Project-2")
```

#### Prepare Data
Source: [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset)  
We will predict the amount of total rental bikes using predictors like time of year or time of the week.  
There are n=731 observations and p=16 variables on the Capital bike sharing system (Washington DC) in 2011-2012:  

1. (ignored!) instant = Record index (like an observation number)  
2. (ignored!) dteday = Date (MM/DD/YYYY format)  
3. season = Categorical numeric var (1:winter, 2:spring, 3:summer, 4:fall)  
4. yr = Year (0:2011, 1:2012)  
5. mnth = Month (1 to 12)  
6. holiday = Whether the day is a holiday or not (1/0)  
7. weekday = Day of the week (0:Sunday to 6:Saturday)  
8. workingday = Whether the day is a working day or weekend/holiday (1/0)  
9. weathersit = Categorical numeric var for weather situation (1:mild to 4:severe)  
    * Clear, Few clouds, Partly cloudy  
    * Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist  
    * Light snow, Light rain + Thunderstorm + Scattered clouds, Light rain + Scattered clouds  
    * Heavy rain + Ice pallets + Thunderstorm + Mist, Snow + Fog  
10. temp = Normalized hourly temp in Celsius (Temp - Min.Temp)/(Max.Temp - Min.Temp) for Min.Temp=-8 & Max.Temp=39  
11. atemp = Normalized hourly feeling temp in Celsius for Min.Temp=-16 & Max.Temp=50  
12. hum = Normalized humidity (Humidity)/(Max.Humidity) for Max.Humidity=100  
13. windspeed = Normalized wind speed (Speed)/(Max.Speed) for Max.Speed=67  
14. (ignored!) casual = Count of casual users  
15. (ignored!) registered = Count of registered users  
16. cnt = Count of total rental bikes (casual + registered)  

We will ignore the `casual` and `registered` variables in our analysis. We will also split the data into analyses by weekday, so 7 separate analyses for each weekday from Sunday (weekday=0) to Saturday (weekday=6). This code is specifically run with `r Per each weekday, we will:  
* Do some preliminary numerical and graphical summaries  
* Split data into 70% training, 30% test data sets  
* Create a tree-based model using leave one out cross-validation  
* Create a boosted tree model using cross-validation  
* Comparison of model performances on the test data set, and selection of a 'best model'  

```{r Prep, cache=TRUE}
# Drop unused data and make factors as needed for categorical vars
bikeData <- read_csv("day.csv", col_names=TRUE) %>% select(-instant, -dteday, -casual, -registered)
bikeData$season <- as.factor(bikeData$season)
bikeData$yr <- as.factor(bikeData$yr)
bikeData$mnth <- as.factor(bikeData$mnth)
bikeData$holiday <- as.factor(bikeData$holiday)
bikeData$weekday <- as.factor(bikeData$weekday)
bikeData$workingday <- as.factor(bikeData$workingday)
bikeData$weathersit <- as.factor(bikeData$weathersit)

# Slice off data for only this weekday (default Sunday)
dayData <- bikeData %>% filter(weekday == params$day)
head(dayData)
n = nrow(dayData)

# Split into 70% training, 30% test data sets
set.seed(123)
train <- sample(1:n, size = n*0.7)
dayData.train <- dayData[train, ]
dayData.test <- dayData[-train, ]
dayData.train
```

#### Explore Data
We see an even spread across the season, yr, mnth variables (as expected across a whole year).  
Most of the days were not a holiday. The weekday corresponds to the report-specific day (as it should!).  

```{r Explore, warnings=FALSE, cache=TRUE}
# Do some basic five-number summaries to check for outliers
summary(dayData)
bikeData[is.na(bikeData)==TRUE]

# Take a look at the numeric, non-factor variables
# Looks like temp, atemp, cnt are clearly bimodal with 2 peaks around indices 20 (May) and 80 (July) when the weather is nice for bike riding!
plot(dayData$temp)
plot(dayData$atemp)
plot(dayData$hum)
plot(dayData$windspeed)
plot(dayData$cnt)

# Do some histograms to check the distributions of numeric, non-factor variables
# Temperature, humidity variables are bimodal as expected
ggplot(data=dayData, aes(x=temp)) + geom_histogram(bins=10, aes(y=..density..)) + 
  geom_density(color="red") + labs(title="Actual Temperature")
ggplot(data=dayData, aes(x=atemp)) + geom_histogram(bins=10, aes(y=..density..)) + 
  geom_density(color="red") + labs(title="Actual Temperature")
ggplot(data=dayData, aes(x=hum)) + geom_histogram(bins=10, aes(y=..density..)) + 
  geom_density(color="red") + labs(title="Humidity")

# Windspeed is a bit skewed right, but we're not doing linear regression. This is ok!
ggplot(data=dayData, aes(x=windspeed)) + geom_histogram(bins=10, aes(y=..density..)) + 
  geom_density(color="red") + labs(title="Windspeed")
# Bike Count shows a huge spread
ggplot(data=dayData, aes(x=cnt)) + geom_histogram(bins=10, aes(y=..density..)) + 
  geom_density(color="red") + labs(title="Bike Count")
```

#### Regression Tree with LOOCV
We will use the caret package to automate LOOCV for "rpart" method for a regression tree.  
Because of LOOCV, this will take awhile on bigger n (we're okay)! Good idea to cache results.  
```{r RegTree LOOCV, cache=TRUE}
tree.cv <- train(cnt ~ .,
                 data = dayData.train,
                 method = "rpart",
                 trControl = trainControl(method="LOOCV"),
                 tuneGrid = expand.grid(cp=seq(0, 0.15, 0.01)))
tree.cv

best.cp <- tree.cv$bestTune$cp
best.rmse <- tree.cv$results$RMSE[tree.cv$results$cp==best.cp]
best.RSquared <- tree.cv$results$Rsquared[tree.cv$results$cp==best.cp]
best.MAE <- tree.cv$results$MAE[tree.cv$results$cp==best.cp]
```

The best complexity parameter was `r tree.cv$bestTune$cp`, based on lowest RMSE (unexplained variation) of `r best.rmse`.  

```{r, cache=TRUE}
tree.cv$finalModel
plot(tree.cv$finalModel, margin=0.2); text(tree.cv$finalModel, cex=0.8)
```

#### Boosted Tree with CV
We can often improve prediction using boosting, which is slow training of trees that are grown sequentially. We make many weak, shallow trees that each grow on a modified version of the original data, with the goal to improve on error rate.  
Because LOOCV can be time-consuming, let's just use 10-fold cross validation. This could still take quite some time if you have a lot of tuning parameters!  
```{r BoostTree CV, warning=FALSE, cache=TRUE}
# Turn warnings off because R will complain about factor levels having 0 variance
# Running this w/o tuneGrid gives n.trees=150, interaction.depth=2, shrinkage=0.1, n.minobsinnode=10
# So, try tuning in those neighborhoods of values
boost.cv <- train(cnt ~ .,
                  data = dayData.train,
                  method = "gbm",
                  distribution = "gaussian",
                  trControl = trainControl(method="cv", number=10),
                  tuneGrid = expand.grid(n.trees=c(1000, 5000, 10000),
                                         interaction.depth=1:4,
                                         shrinkage=c(0.01, 0.1),
                                         n.minobsinnode=c(1,5,10)),
                  verbose = FALSE)
boost.cv$bestTune
```

# Second Analysis  
## Linear model  

```{r}
lm.fit <- lm(cnt~temp+windspeed+atemp+hum, data =dayData.train)
summary(lm.fit)
final.fit <- train(as.formula(cnt~temp+windspeed+atemp+hum),
              dayData.test,method='lm',
              trControl = trainControl(method = 'cv',number=5))
final.fit$results$RMSE
```


#### Final Model
We compare the final models selected from `tree.cv` ,`boost.cv` and `linear model`for best performance on the test dataset. We measure performance as the smallest RMSE (root mean squared error), which reflects unexplained variation. Then, we'll take the best model and report it's parameters.  
```{r FinalModel, cache=TRUE}
regPred <- predict(tree.cv, newdata=dayData.test)
reg.rmse <- sqrt(mean((regPred - dayData.test$cnt)^2))

boostPred <- predict(boost.cv, newdata=dayData.test)
boost.rmse <- sqrt(mean((boostPred - dayData.test$cnt)^2))

RMSE.vals <- data.frame(c(reg.rmse, boost.rmse,final.fit$results$RMSE))
rownames(RMSE.vals) <- c("Regression Tree", "Boosted Tree","linear model")
colnames(RMSE.vals) <- "RMSE"
kable(RMSE.vals)

```
We prefer the model with lower RMSE.We found that linear model is the optimal model.

#### R Markdown Automation Code
Please don't run this when knitting Project2.Rmd! You'll want to run this separately (like in the Console) to get all the reports. Just putting this here so it doesn't get lost! You can access these R Markdwon parameters using `params$weekday` in the R Code during each automated run.
```{r Automate, eval=FALSE}
days <- c("Sunday", "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")
outFiles <- paste0(days, "Analysis.md")
for (i in 1:7){
  rmarkdown::render("Project2.Rmd", output_file=outFiles[i], params=list(day=(i-1)))
}
```

